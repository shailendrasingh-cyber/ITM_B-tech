{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df867bd",
   "metadata": {},
   "source": [
    "# Heart Dataset Analysis and ML Models\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA), preprocessing, and trains multiple classification models using a single reusable function. It includes evaluation metrics, confusion matrices, and ROC curves. The dataset is loaded from `/mnt/data/heart.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea112a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             confusion_matrix, roc_curve, auc, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r'/mnt/data/heart.csv')\n",
    "print('Dataset loaded:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info and missing values\n",
    "print(df.info())\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "print('\\nSummary statistics:\\n', df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple univariate plots for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Numeric columns:', numeric_cols)\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6,2.2))\n",
    "    plt.hist(df[col].dropna(), bins=20)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix heatmap (matplotlib)\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr)), corr.index)\n",
    "plt.title('Correlation matrix (heatmap)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: simple steps\n",
    "# Assumes target column is named 'target' or 'Target' or 'heart_disease' - try common names\n",
    "possible_targets = ['target','Target','heart_disease','HeartDisease','output']\n",
    "target_col = None\n",
    "for t in possible_targets:\n",
    "    if t in df.columns:\n",
    "        target_col = t\n",
    "        break\n",
    "if target_col is None:\n",
    "    # fallback: last column as target\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print('Using target column:', target_col)\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Handle categorical columns (one-hot encode), handle missing by simple imputation\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Standard scaling for numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print('Preprocessed X shape:', X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ee8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single function that trains multiple models, returns a summary and plots results\n",
    "def run_models(models, X_train, y_train, X_test, y_test, cv=5):\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for name, model in models:\n",
    "        # cross-validated accuracy and roc_auc (if probability available)\n",
    "        acc_cv = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy').mean()\n",
    "        try:\n",
    "            roc_cv = cross_val_score(model, X_train, y_train, cv=skf, scoring='roc_auc').mean()\n",
    "        except Exception:\n",
    "            roc_cv = np.nan\n",
    "        # fit on train\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        probs = None\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probs = model.predict_proba(X_test)[:,1]\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            try:\n",
    "                probs = model.decision_function(X_test)\n",
    "            except Exception:\n",
    "                probs = None\n",
    "        # metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc = roc_auc_score(y_test, probs) if probs is not None and len(np.unique(y_test))==2 else np.nan\n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'cv_accuracy': acc_cv,\n",
    "            'cv_roc_auc': roc_cv,\n",
    "            'test_accuracy': acc,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc\n",
    "        })\n",
    "        # Plot ROC curve if possible\n",
    "        if probs is not None and len(np.unique(y_test))==2:\n",
    "            fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "            plt.plot(fpr, tpr, label=f'{name} (AUC={roc:.3f})' if not np.isnan(roc) else name)\n",
    "    # finalize ROC plot\n",
    "    plt.plot([0,1],[0,1],'--', label='random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curves (for models with probability output)')\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb667714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to evaluate\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=1000)),\n",
    "    ('RandomForest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('GradientBoosting', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('KNeighbors', KNeighborsClassifier()),\n",
    "    ('SVC', SVC(probability=True))\n",
    "]\n",
    "\n",
    "results_df = run_models(models, X_train, y_train, X_test, y_test, cv=5)\n",
    "results_df.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc77e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report and confusion matrix for the best model (by test accuracy)\n",
    "best_name = results_df.sort_values('test_accuracy', ascending=False).iloc[0]['model']\n",
    "print('Best model:', best_name)\n",
    "best_model = None\n",
    "for name, model in models:\n",
    "    if name == best_name:\n",
    "        best_model = model\n",
    "        break\n",
    "# Refit best model on full training set and evaluate\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(f'Confusion matrix - {best_name}')\n",
    "plt.xticks([0,1])\n",
    "plt.yticks([0,1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92879dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and the scaler to disk for later use\n",
    "with open('/mnt/data/best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "with open('/mnt/data/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print('Saved best model to /mnt/data/best_model.pkl and scaler to /mnt/data/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69620fdf",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This notebook is generated automatically. You can open and run it in Jupyter or VS Code.\n",
    "- If the target column name is different, the notebook falls back to using the last column as target.\n",
    "- The `run_models` function runs cross-validation, fits models, plots ROC curves for models that return probabilities, and returns a performance summary."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

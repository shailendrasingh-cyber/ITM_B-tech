{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35ab7e2-b384-42a0-8ad0-9f32d4d50374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 303543877632.0000 - mae: 403076.6250 - val_loss: 196823842816.0000 - val_mae: 336985.2500\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 303542468608.0000 - mae: 403074.7188 - val_loss: 196821401600.0000 - val_mae: 336981.6875\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 303537225728.0000 - mae: 403068.1875 - val_loss: 196812783616.0000 - val_mae: 336969.2188\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 303520219136.0000 - mae: 403046.6875 - val_loss: 196786438144.0000 - val_mae: 336931.7500\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 303470870528.0000 - mae: 402986.3750 - val_loss: 196718657536.0000 - val_mae: 336836.8125\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 303354347520.0000 - mae: 402848.1875 - val_loss: 196571611136.0000 - val_mae: 336633.0312\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 303124676608.0000 - mae: 402566.9375 - val_loss: 196288479232.0000 - val_mae: 336243.9062\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 302691614720.0000 - mae: 402062.5312 - val_loss: 195805872128.0000 - val_mae: 335580.8438\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 301995524096.0000 - mae: 401228.5312 - val_loss: 195030859776.0000 - val_mae: 334516.2500\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 300961824768.0000 - mae: 399962.9688 - val_loss: 193879572480.0000 - val_mae: 332932.5625\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 299350851584.0000 - mae: 398092.3750 - val_loss: 192237862912.0000 - val_mae: 330663.5312\n",
      "Epoch 12/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 297131638784.0000 - mae: 395433.9688 - val_loss: 189965729792.0000 - val_mae: 327504.0625\n",
      "Epoch 13/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 294143295488.0000 - mae: 391856.8750 - val_loss: 186925137920.0000 - val_mae: 323231.7812\n",
      "Epoch 14/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 290122366976.0000 - mae: 387038.1562 - val_loss: 183027138560.0000 - val_mae: 317691.9375\n",
      "Epoch 15/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 285060825088.0000 - mae: 380875.9688 - val_loss: 178199248896.0000 - val_mae: 310684.7500\n",
      "Epoch 16/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 278891855872.0000 - mae: 373087.9375 - val_loss: 172296830976.0000 - val_mae: 301889.5000\n",
      "Epoch 17/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 271655878656.0000 - mae: 363694.0625 - val_loss: 165323882496.0000 - val_mae: 291189.5000\n",
      "Epoch 18/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 262488965120.0000 - mae: 352036.4062 - val_loss: 157394534400.0000 - val_mae: 278619.5000\n",
      "Epoch 19/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 252593209344.0000 - mae: 338471.9062 - val_loss: 148264730624.0000 - val_mae: 264059.6875\n",
      "Epoch 20/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 241711710208.0000 - mae: 322820.1562 - val_loss: 138273701888.0000 - val_mae: 247326.5469\n",
      "Epoch 21/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 228465950720.0000 - mae: 304725.6562 - val_loss: 128135462912.0000 - val_mae: 230185.1406\n",
      "Epoch 22/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 216233820160.0000 - mae: 286020.9062 - val_loss: 117741510656.0000 - val_mae: 212100.6875\n",
      "Epoch 23/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 202489790464.0000 - mae: 267222.4688 - val_loss: 107221499904.0000 - val_mae: 193807.3750\n",
      "Epoch 24/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 190481154048.0000 - mae: 249902.1562 - val_loss: 98101911552.0000 - val_mae: 178672.5000\n",
      "Epoch 25/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 177916346368.0000 - mae: 234746.3750 - val_loss: 89530916864.0000 - val_mae: 167520.5469\n",
      "Epoch 26/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 165847138304.0000 - mae: 221201.5156 - val_loss: 82010546176.0000 - val_mae: 160180.1875\n",
      "Epoch 27/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 157517889536.0000 - mae: 211932.8438 - val_loss: 76283076608.0000 - val_mae: 157243.2344\n",
      "Epoch 28/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 149253505024.0000 - mae: 204518.3281 - val_loss: 72360353792.0000 - val_mae: 157061.7500\n",
      "Epoch 29/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 141081247744.0000 - mae: 201224.2812 - val_loss: 69438267392.0000 - val_mae: 158225.4688\n",
      "Epoch 30/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 135813611520.0000 - mae: 197618.4375 - val_loss: 67353432064.0000 - val_mae: 160795.4844\n",
      "Epoch 31/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 131121979392.0000 - mae: 196073.9531 - val_loss: 65972076544.0000 - val_mae: 163834.4219\n",
      "Epoch 32/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 129458511872.0000 - mae: 197995.8438 - val_loss: 64987410432.0000 - val_mae: 165711.9688\n",
      "Epoch 33/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 126277795840.0000 - mae: 199011.0469 - val_loss: 64127553536.0000 - val_mae: 165750.2031\n",
      "Epoch 34/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 123822096384.0000 - mae: 195159.1250 - val_loss: 63368843264.0000 - val_mae: 166503.1875\n",
      "Epoch 35/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 121914556416.0000 - mae: 197662.1875 - val_loss: 62693814272.0000 - val_mae: 166783.3906\n",
      "Epoch 36/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 119966310400.0000 - mae: 194065.1250 - val_loss: 62040772608.0000 - val_mae: 166992.6406\n",
      "Epoch 37/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 117828870144.0000 - mae: 193705.5000 - val_loss: 61250756608.0000 - val_mae: 166038.3125\n",
      "Epoch 38/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 115269861376.0000 - mae: 192905.9844 - val_loss: 60735623168.0000 - val_mae: 166560.3594\n",
      "Epoch 39/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 116389740544.0000 - mae: 192092.4062 - val_loss: 59853549568.0000 - val_mae: 164680.3125\n",
      "Epoch 40/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 111363457024.0000 - mae: 187216.4375 - val_loss: 59114065920.0000 - val_mae: 163366.3125\n",
      "Epoch 41/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 112256008192.0000 - mae: 187384.3125 - val_loss: 58898984960.0000 - val_mae: 164858.0312\n",
      "Epoch 42/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 110493917184.0000 - mae: 187760.4844 - val_loss: 58166636544.0000 - val_mae: 163390.6719\n",
      "Epoch 43/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 109588930560.0000 - mae: 186488.4219 - val_loss: 57670524928.0000 - val_mae: 163233.7969\n",
      "Epoch 44/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 109042507776.0000 - mae: 187656.8906 - val_loss: 57242918912.0000 - val_mae: 163228.5469\n",
      "Epoch 45/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 107596578816.0000 - mae: 185209.8594 - val_loss: 56772825088.0000 - val_mae: 163010.7812\n",
      "Epoch 46/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 102147276800.0000 - mae: 180534.4219 - val_loss: 56056905728.0000 - val_mae: 161471.6719\n",
      "Epoch 47/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 103071965184.0000 - mae: 182185.0312 - val_loss: 55445647360.0000 - val_mae: 160426.2656\n",
      "Epoch 48/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 103985995776.0000 - mae: 182330.9688 - val_loss: 54837596160.0000 - val_mae: 159304.2031\n",
      "Epoch 49/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 103297941504.0000 - mae: 181613.2969 - val_loss: 54221254656.0000 - val_mae: 158115.7031\n",
      "Epoch 50/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 102393020416.0000 - mae: 178367.1406 - val_loss: 53601275904.0000 - val_mae: 156792.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 98802925568.0000 - mae: 175431.2031 - val_loss: 53286907904.0000 - val_mae: 157116.4844\n",
      "Epoch 52/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 97588838400.0000 - mae: 175900.9375 - val_loss: 52529635328.0000 - val_mae: 155024.7969\n",
      "Epoch 53/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 99166625792.0000 - mae: 175940.4688 - val_loss: 51829194752.0000 - val_mae: 153087.8281\n",
      "Epoch 54/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 95755091968.0000 - mae: 171199.5625 - val_loss: 51398496256.0000 - val_mae: 152600.9219\n",
      "Epoch 55/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 94184857600.0000 - mae: 170801.2344 - val_loss: 50964434944.0000 - val_mae: 151981.6875\n",
      "Epoch 56/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 94538178560.0000 - mae: 169653.0938 - val_loss: 50566557696.0000 - val_mae: 151726.9844\n",
      "Epoch 57/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 91536605184.0000 - mae: 166588.4688 - val_loss: 50231066624.0000 - val_mae: 151570.0312\n",
      "Epoch 58/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 91261116416.0000 - mae: 170460.6094 - val_loss: 49509687296.0000 - val_mae: 149569.6719\n",
      "Epoch 59/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 93329891328.0000 - mae: 172223.7500 - val_loss: 49336131584.0000 - val_mae: 150542.9688\n",
      "Epoch 60/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 91060961280.0000 - mae: 169706.8281 - val_loss: 49041403904.0000 - val_mae: 150817.8125\n",
      "Epoch 61/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 90329243648.0000 - mae: 166914.4062 - val_loss: 48569974784.0000 - val_mae: 150109.7344\n",
      "Epoch 62/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 89815408640.0000 - mae: 167216.2031 - val_loss: 47694942208.0000 - val_mae: 147409.2969\n",
      "Epoch 63/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 86160351232.0000 - mae: 160081.6875 - val_loss: 46974148608.0000 - val_mae: 145495.8125\n",
      "Epoch 64/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 85710708736.0000 - mae: 163192.3750 - val_loss: 46501285888.0000 - val_mae: 144644.5312\n",
      "Epoch 65/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 86481543168.0000 - mae: 161561.5312 - val_loss: 45929066496.0000 - val_mae: 143398.3906\n",
      "Epoch 66/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 86982066176.0000 - mae: 165161.0312 - val_loss: 45750788096.0000 - val_mae: 144145.3281\n",
      "Epoch 67/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 84061749248.0000 - mae: 161856.9062 - val_loss: 44988362752.0000 - val_mae: 141895.3906\n",
      "Epoch 68/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 84392919040.0000 - mae: 160138.7188 - val_loss: 44427010048.0000 - val_mae: 140641.0469\n",
      "Epoch 69/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 82933440512.0000 - mae: 160134.9531 - val_loss: 43908190208.0000 - val_mae: 139581.2031\n",
      "Epoch 70/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 80413097984.0000 - mae: 155357.1250 - val_loss: 43398426624.0000 - val_mae: 138576.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 83406471168.0000 - mae: 158189.9062 - val_loss: 42854658048.0000 - val_mae: 137313.5312\n",
      "Epoch 72/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 81363410944.0000 - mae: 157859.1094 - val_loss: 42601566208.0000 - val_mae: 137916.2656\n",
      "Epoch 73/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 77432356864.0000 - mae: 154611.7344 - val_loss: 42212843520.0000 - val_mae: 137672.3281\n",
      "Epoch 74/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 77693648896.0000 - mae: 154748.0000 - val_loss: 41757913088.0000 - val_mae: 137019.2031\n",
      "Epoch 75/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 75843444736.0000 - mae: 153205.9219 - val_loss: 41052262400.0000 - val_mae: 135051.7656\n",
      "Epoch 76/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 76109684736.0000 - mae: 149013.0469 - val_loss: 40373870592.0000 - val_mae: 133197.6719\n",
      "Epoch 77/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 75209613312.0000 - mae: 148736.2812 - val_loss: 39711723520.0000 - val_mae: 131282.6250\n",
      "Epoch 78/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 73599016960.0000 - mae: 148372.9375 - val_loss: 39671894016.0000 - val_mae: 133254.3281\n",
      "Epoch 79/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 71091683328.0000 - mae: 146510.6719 - val_loss: 39098834944.0000 - val_mae: 132031.8750\n",
      "Epoch 80/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 70820495360.0000 - mae: 146763.1094 - val_loss: 38390030336.0000 - val_mae: 129795.5859\n",
      "Epoch 81/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 68874264576.0000 - mae: 143006.5781 - val_loss: 37890482176.0000 - val_mae: 128927.7109\n",
      "Epoch 82/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 69325504512.0000 - mae: 144543.5938 - val_loss: 37480951808.0000 - val_mae: 128652.1641\n",
      "Epoch 83/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 70657785856.0000 - mae: 144710.7344 - val_loss: 37286952960.0000 - val_mae: 129812.4297\n",
      "Epoch 84/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 67734138880.0000 - mae: 142142.6406 - val_loss: 36954226688.0000 - val_mae: 130093.5703\n",
      "Epoch 85/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 66031550464.0000 - mae: 144008.0938 - val_loss: 36474699776.0000 - val_mae: 129295.8203\n",
      "Epoch 86/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 66218622976.0000 - mae: 142462.3281 - val_loss: 35767119872.0000 - val_mae: 127226.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 63642492928.0000 - mae: 139288.8438 - val_loss: 35120414720.0000 - val_mae: 125534.5547\n",
      "Epoch 88/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 63945195520.0000 - mae: 139134.3750 - val_loss: 34456416256.0000 - val_mae: 123463.8281\n",
      "Epoch 89/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 64594587648.0000 - mae: 138459.1719 - val_loss: 34018967552.0000 - val_mae: 122944.7891\n",
      "Epoch 90/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 62394347520.0000 - mae: 136622.0938 - val_loss: 33329076224.0000 - val_mae: 120724.8203\n",
      "Epoch 91/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 61123284992.0000 - mae: 134427.7969 - val_loss: 33030275072.0000 - val_mae: 121132.4141\n",
      "Epoch 92/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 59834114048.0000 - mae: 132812.3281 - val_loss: 32351879168.0000 - val_mae: 118801.4297\n",
      "Epoch 93/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 59899260928.0000 - mae: 130844.5469 - val_loss: 32000190464.0000 - val_mae: 118810.1250\n",
      "Epoch 94/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 60994686976.0000 - mae: 132063.1094 - val_loss: 31630190592.0000 - val_mae: 118469.2891\n",
      "Epoch 95/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 60086099968.0000 - mae: 133250.0938 - val_loss: 31220512768.0000 - val_mae: 117978.4375\n",
      "Epoch 96/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 57276751872.0000 - mae: 129632.6172 - val_loss: 30799478784.0000 - val_mae: 117448.1250\n",
      "Epoch 97/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 56147243008.0000 - mae: 128272.4609 - val_loss: 30229577728.0000 - val_mae: 115740.4922\n",
      "Epoch 98/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 56364826624.0000 - mae: 126119.2109 - val_loss: 29820909568.0000 - val_mae: 115136.4062\n",
      "Epoch 99/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 54982438912.0000 - mae: 126792.9453 - val_loss: 29280720896.0000 - val_mae: 113881.8281\n",
      "Epoch 100/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 54326382592.0000 - mae: 124897.7656 - val_loss: 28703160320.0000 - val_mae: 112399.7969\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 119121248256.0000 - mae: 178992.5625 \n",
      "Test Loss (MSE): 119121248256.00\n",
      "Test MAE: 178992.56\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Predicted Price: ₹414569.53\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# STEP 1: Import Libraries\n",
    "# =======================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# =======================\n",
    "# STEP 2: Load Dataset\n",
    "# =======================\n",
    "data = pd.read_csv('cleaned car.csv')\n",
    "\n",
    "# Drop unnecessary column\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# =======================\n",
    "# STEP 3: Define Features & Target\n",
    "# =======================\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "\n",
    "# =======================\n",
    "# STEP 4: Preprocessing (Encoding + Scaling)\n",
    "# =======================\n",
    "categorical_cols = ['name', 'company', 'fuel_type']\n",
    "numerical_cols = ['year', 'kms_driven']\n",
    "\n",
    "# One-Hot Encode categorical columns & scale numeric\n",
    "ct = ColumnTransformer([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('scaler', StandardScaler(), numerical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X_processed = ct.fit_transform(X)\n",
    "\n",
    "# =======================\n",
    "# STEP 5: Train-Test Split\n",
    "# =======================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =======================\n",
    "# STEP 6: Build ANN Model\n",
    "# =======================\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])\n",
    "\n",
    "# =======================\n",
    "# STEP 7: Compile Model\n",
    "# =======================\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# =======================\n",
    "# STEP 8: Train Model\n",
    "# =======================\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# =======================\n",
    "# STEP 9: Evaluate Model\n",
    "# =======================\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss (MSE): {loss:.2f}\")\n",
    "print(f\"Test MAE: {mae:.2f}\")\n",
    "\n",
    "# =======================\n",
    "# STEP 10: Predict New Car Price\n",
    "# =======================\n",
    "sample = pd.DataFrame({\n",
    "    'name': ['Hyundai i10'],\n",
    "    'company': ['Hyundai'],\n",
    "    'year': [2015],\n",
    "    'kms_driven': [35000],\n",
    "    'fuel_type': ['Petrol']\n",
    "})\n",
    "\n",
    "sample_transformed = ct.transform(sample)\n",
    "predicted_price = model.predict(sample_transformed)\n",
    "print(f\"Predicted Price: ₹{predicted_price[0][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d350d-8716-4b91-ba8f-02c2be47554a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
